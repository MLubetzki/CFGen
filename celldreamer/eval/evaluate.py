import pandas as pd
import numpy as np
from celldreamer.eval.optimal_transport import wasserstein
from celldreamer.eval.distribution_distances import compute_distribution_distances
import scanpy as sc
import numpy as np
import sklearn.metrics

def scanpy_pipeline(adata):
    """
    Preprocesses an AnnData object using Scanpy's preprocessing pipeline.

    Parameters:
        adata (AnnData): Annotated Data object.

    Returns:
        AnnData: Processed AnnData object.
    """
    # sc.pp.log1p(adata)
    sc.tl.pca(adata)
    sc.pp.neighbors(adata)
    sc.tl.umap(adata)
    return adata

def plot_and_save_umap(adata, plotting_folder, epoch, real_and_fake_dataset=False):
    """
    Plots and saves the UMAP (Uniform Manifold Approximation and Projection) of an AnnData object.

    Parameters:
        adata (AnnData): Annotated Data object.
        plotting_folder (str): Path to the folder where the UMAP plot should be saved.
    """
    # Set the plotting directory
    sc.settings.figdir = str(plotting_folder)
    if not real_and_fake_dataset:
        sc.pl.pca(adata, show=False, save=f"generated_pca_{epoch}.png")
        sc.pl.umap(adata, show=False, save=f"generated_umap_{epoch}.png")
    else:
        sc.pl.pca(adata, color="dataset_type", show=False, save=f"generated_pca_real_fake_{epoch}.png")
        sc.pl.umap(adata, color="dataset_type", show=False, save=f"generated_umap_real_fake_{epoch}.png") 

def compute_umap_and_wasserstein(model, 
                                    batch_size, 
                                    n_sample_steps, 
                                    plotting_folder, 
                                    X_real, 
                                    epoch,
                                    theta_covariate,
                                    size_factor_covariate):
    """
    Generates UMAP plot for samples generated by a given model.

    Parameters:
        model: The generative model.
        batch_size (int): Number of samples to generate.
        n_sample_steps (int): Number of steps for sampling.
        library_size (float): Size of the generated library.
        plotting_folder (str): Path to the folder where the UMAP plot should be saved.
        X_real (torch.Tensor): tensor containing concatenated test data. 

    Returns:
        AnnData: Annotated Data object containing the generated samples with UMAP coordinates.
    """
    # Generate data and compute Wasserstein distance from test data
    if not model.multimodal: 
        modality_list = ["rna"]
    else:
        modality_list = model.modality_list

    # Sample batches 
    repetitions  = batch_size // 100
    X_generated_dict = model.batched_sample(100, 
                                            repetitions,
                                            n_sample_steps, 
                                            theta_covariate,
                                            size_factor_covariate, 
                                            conditioning_covariates=model.covariate_list)
    
    # Collect into a dictionary 
    if len(modality_list)==1:
        X_generated_dict = {"rna": X_generated_dict}
        X_real = {"rna": X_real}
    
    # Calculate metrics per modality 
    wd = {}
    for mod in modality_list:
        X_generated = X_generated_dict[mod].cpu()
        wd_mod = compute_distribution_distances(X_generated, X_real[mod])
        wd_mod = {f"{key}_{mod}":val for key,val in wd_mod.items()}
        wd.update(wd_mod)
        # Compute and plot UMAP of generated data
        X_generated = X_generated.numpy()
        adata_generated = sc.AnnData(X=X_generated.copy())
        adata_generated = scanpy_pipeline(adata_generated)
        plot_and_save_umap(adata_generated, plotting_folder / mod, epoch, real_and_fake_dataset=False)
        
        # Process the real data, take logarithm and compute UMAP 
        X = np.concatenate([X_generated, 
                            X_real[mod].numpy()], axis=0) 
        annot = ["generated" for _ in range(len(X_generated))]  + ["real" for _ in range(len(X_real[mod]))]
        annot_df = pd.DataFrame({"dataset_type": annot})
        adata_real_fake = sc.AnnData(X=X, obs=annot_df)
        adata_real_fake = scanpy_pipeline(adata_real_fake)
        plot_and_save_umap(adata_real_fake, plotting_folder / mod, epoch, real_and_fake_dataset=True)    
    return wd

def compute_pairwise_distance(data_x, data_y=None):
    """
    Args:
        data_x: numpy.ndarray([N, feature_dim], dtype=np.float32)
        data_y: numpy.ndarray([N, feature_dim], dtype=np.float32)
    Returns:
        numpy.ndarray([N, N], dtype=np.float32) of pairwise distances.
    """
    if data_y is None:
        data_y = data_x
    dists = sklearn.metrics.pairwise_distances(
        data_x, data_y, metric='euclidean', n_jobs=8)
    return dists

def get_kth_value(unsorted, k, axis=-1):
    """
    Args:
        unsorted: numpy.ndarray of any dimensionality.
        k: int
    Returns:
        kth values along the designated axis.
    """
    indices = np.argpartition(unsorted, k, axis=axis)[..., :k]
    k_smallests = np.take_along_axis(unsorted, indices, axis=axis)
    kth_values = k_smallests.max(axis=axis)
    return kth_values


def compute_nearest_neighbour_distances(input_features, nearest_k):
    """
    Args:
        input_features: numpy.ndarray([N, feature_dim], dtype=np.float32)
        nearest_k: int
    Returns:
        Distances to kth nearest neighbours.
    """
    distances = compute_pairwise_distance(input_features)
    radii = get_kth_value(distances, k=nearest_k + 1, axis=-1)
    return radii


def compute_prdc(real_features, fake_features, nearest_k):
    """
    Computes precision, recall, density, and coverage given two manifolds.

    Args:
        real_features: numpy.ndarray([N, feature_dim], dtype=np.float32)
        fake_features: numpy.ndarray([N, feature_dim], dtype=np.float32)
        nearest_k: int.
    Returns:
        dict of precision, recall, density, and coverage.
    """

    print('Num real: {} Num fake: {}'
          .format(real_features.shape[0], fake_features.shape[0]))

    real_nearest_neighbour_distances = compute_nearest_neighbour_distances(
        real_features, nearest_k)
    fake_nearest_neighbour_distances = compute_nearest_neighbour_distances(
        fake_features, nearest_k)
    distance_real_fake = compute_pairwise_distance(
        real_features, fake_features)

    precision = (
            distance_real_fake <
            np.expand_dims(real_nearest_neighbour_distances, axis=1)
    ).any(axis=0).mean()

    recall = (
            distance_real_fake <
            np.expand_dims(fake_nearest_neighbour_distances, axis=0)
    ).any(axis=1).mean()

    density = (1. / float(nearest_k)) * (
            distance_real_fake <
            np.expand_dims(real_nearest_neighbour_distances, axis=1)
    ).sum(axis=0).mean()

    coverage = (
            distance_real_fake.min(axis=1) <
            real_nearest_neighbour_distances
    ).mean()

    return dict(precision=precision, recall=recall,
                density=density, coverage=coverage)
    