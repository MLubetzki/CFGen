{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1373949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor, TQDMProgressBar\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.utilities.model_summary import ModelSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36062db8-7598-42ec-9675-d31ef7ed79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c26f259-4696-43f9-b9dd-d45b87c2bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from celldreamer.paths import ROOT\n",
    "from celldreamer.estimator.celldreamer_estimator import CellDreamerEstimator\n",
    "from celldreamer.paths import DATA_DIR\n",
    "from celldreamer.data.utils import Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6b23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/icb/till.richter/git/celldreamer\n"
     ]
    }
   ],
   "source": [
    "cd $ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87658dd9",
   "metadata": {},
   "source": [
    "Load configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5a4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open(ROOT / \"configs/toy/config_ddpm.yaml\", \n",
    "                            \"rb\"))\n",
    "args_toy = Args(config[\"args\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e50e1a",
   "metadata": {},
   "source": [
    "Initialize estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a35736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the training folders...\n",
      "Initialize data module...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id rya9e5u5.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize feature embeddings...\n",
      "Initialize model...\n"
     ]
    }
   ],
   "source": [
    "estimator = CellDreamerEstimator(args_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec62f367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConditionalGaussianDDPM(\n",
       "  (denoising_model): UNetTimeStepClassSetConditioned(\n",
       "    (downsample_blocks): ModuleList(\n",
       "      (0): ResBlockTimeEmbedCond(\n",
       "        (linear_map_class): Identity()\n",
       "        (time_embed_net): Sequential(\n",
       "          (0): Linear(in_features=100, out_features=32, bias=True)\n",
       "          (1): SELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (conv): Sequential(\n",
       "          (0): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "        (l_embedding): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=100, out_features=32, bias=True)\n",
       "        )\n",
       "        (out_layer): Sequential(\n",
       "          (0): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): ResBlockTimeEmbedCond(\n",
       "        (linear_map_class): Identity()\n",
       "        (time_embed_net): Sequential(\n",
       "          (0): Linear(in_features=100, out_features=64, bias=True)\n",
       "          (1): SELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv): Sequential(\n",
       "          (0): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "        (l_embedding): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=100, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layer): Sequential(\n",
       "          (0): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (2): ResBlockTimeEmbedCond(\n",
       "        (linear_map_class): Identity()\n",
       "        (time_embed_net): Sequential(\n",
       "          (0): Linear(in_features=100, out_features=128, bias=True)\n",
       "          (1): SELU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (conv): Sequential(\n",
       "          (0): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "        (l_embedding): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=100, out_features=128, bias=True)\n",
       "        )\n",
       "        (out_layer): Sequential(\n",
       "          (0): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (downsample_op): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (middle_block): ResBlockTimeEmbedCond(\n",
       "      (linear_map_class): Identity()\n",
       "      (time_embed_net): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=128, bias=True)\n",
       "        (1): SELU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "      (l_embedding): Sequential(\n",
       "        (0): GELU(approximate='none')\n",
       "        (1): Linear(in_features=100, out_features=128, bias=True)\n",
       "      )\n",
       "      (out_layer): Sequential(\n",
       "        (0): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (upsample_blocks): ModuleList(\n",
       "      (0): ResBlockTimeEmbedCond(\n",
       "        (linear_map_class): Identity()\n",
       "        (time_embed_net): Sequential(\n",
       "          (0): Linear(in_features=100, out_features=64, bias=True)\n",
       "          (1): SELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (conv): Sequential(\n",
       "          (0): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "        (l_embedding): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=100, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layer): Sequential(\n",
       "          (0): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): ResBlockTimeEmbedCond(\n",
       "        (linear_map_class): Identity()\n",
       "        (time_embed_net): Sequential(\n",
       "          (0): Linear(in_features=100, out_features=32, bias=True)\n",
       "          (1): SELU()\n",
       "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (conv): Sequential(\n",
       "          (0): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "        (l_embedding): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=100, out_features=32, bias=True)\n",
       "        )\n",
       "        (out_layer): Sequential(\n",
       "          (0): GroupNorm(4, 32, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (2): ResBlockTimeEmbedCond(\n",
       "        (linear_map_class): Identity()\n",
       "        (time_embed_net): Sequential(\n",
       "          (0): Linear(in_features=100, out_features=3, bias=True)\n",
       "          (1): SELU()\n",
       "          (2): Linear(in_features=3, out_features=3, bias=True)\n",
       "        )\n",
       "        (conv): Sequential(\n",
       "          (0): GroupNorm(4, 64, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "        (l_embedding): Sequential(\n",
       "          (0): GELU(approximate='none')\n",
       "          (1): Linear(in_features=100, out_features=3, bias=True)\n",
       "        )\n",
       "        (out_layer): Sequential(\n",
       "          (0): GroupNorm(3, 3, eps=1e-05, affine=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (dropouts): ModuleList(\n",
       "      (0-2): 3 x Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (self_attn): ImageSelfAttention(\n",
       "      (attn_layer): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (time_embed): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (mse): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.generative_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52ec7b4-6089-4d3c-b346-ef79893182ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m position_labels \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_positions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# create a matplotlib figure with 4x4 images with the title of each sub-image being the set of labels\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# increase distance between subplots\u001b[39;00m\n\u001b[1;32m     16\u001b[0m fig\u001b[38;5;241m.\u001b[39msubplots_adjust(hspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, wspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# sample images from the toy dataset\n",
    "shapes = [\"circle\", \"square\"]\n",
    "colors = [\"lightblue\", \"lightgreen\", \"lightyellow\", \"lightgray\"]\n",
    "sizes = [\"small\", \"medium\", \"large\"]\n",
    "positions = [\"topleft\", \"topright\", \"bottomleft\", \"bottomright\"]\n",
    "for data in estimator.datamodule.train_dataloader():\n",
    "    images = data['X']\n",
    "    y = data['y']\n",
    "    shape_labels = y['y_shapes']\n",
    "    color_labels = y['y_colors']\n",
    "    size_labels = y['y_sizes']\n",
    "    position_labels = y['y_positions']\n",
    "    # create a matplotlib figure with 4x4 images with the title of each sub-image being the set of labels\n",
    "    fig, ax = plt.subplots(4, 4, figsize=(10, 10))\n",
    "    # increase distance between subplots\n",
    "    fig.subplots_adjust(hspace=0.6, wspace=0.6)\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            ax[i, j].imshow(images[i*4+j].permute(1, 2, 0))\n",
    "            ax[i, j].set_title(f'{sizes[size_labels[i*4+j]]} {colors[color_labels[i*4+j]]} \\n {shapes[shape_labels[i*4+j]]} at {positions[position_labels[i*4+j]]}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5db26",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1145dda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                            | Params\n",
      "--------------------------------------------------------------------\n",
      "0 | denoising_model | UNetTimeStepClassSetConditioned | 1.3 M \n",
      "1 | mse             | MSELoss                         | 0     \n",
      "--------------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.070     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0b0605461c4bbe8c1fc09d34eb6aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/celldreamer/celldreamer/estimator/celldreamer_estimator.py:346\u001b[0m, in \u001b[0;36mCellDreamerEstimator.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_latent_repr \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtrain_autoencoder:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# Fit autoencoder model \u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer_autoencoder\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder,\n\u001b[1;32m    341\u001b[0m         train_dataloaders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39mtrain_dataloader,\n\u001b[1;32m    342\u001b[0m         val_dataloaders\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39mvalid_dataloader,\n\u001b[1;32m    343\u001b[0m         ckpt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpretrained_autoencoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mcheckpoint_autoencoder\n\u001b[1;32m    344\u001b[0m         )\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer_generative\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerative_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_generative\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_generative\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[38;5;241m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1204\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1276\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    151\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 152\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:194\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_skip()\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:84\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.on_run_start\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_dataloader_state_dict(data_fetcher)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# creates the iterator inside the fetcher but returns `self`\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# add the previous `fetched` value to properly track `is_last_batch` with no prefetching\u001b[39;00m\n\u001b[1;32m     86\u001b[0m data_fetcher\u001b[38;5;241m.\u001b[39mfetched \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mready\n",
      "File \u001b[0;32m~/anaconda3/envs/celldreamer/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:178\u001b[0m, in \u001b[0;36mAbstractDataFetcher.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbstractDataFetcher\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_patch()\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetching()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not iterable"
     ]
    }
   ],
   "source": [
    "estimator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2255e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.generative_model = estimator.generative_model.to(\"cuda\")\n",
    "estimator.generative_model.denoising_model = estimator.generative_model.denoising_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt = torch.load(\"/nfs/students/pala/celldreamer/try_experiment_pbmc/checkpoints/epoch_270.ckpt\")\n",
    "# estimator.generative_model.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265cfa87",
   "metadata": {},
   "source": [
    "**Generate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14338918",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = estimator.generative_model.T\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e642103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = torch.randn(10, 50).to(\"cuda\")\n",
    "t1 = 1000*torch.ones(10).to(\"cuda\")\n",
    "t2 = 1*torch.ones(10).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0178a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.generative_model.denoising_model(vec, t1, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3b7d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.generative_model.denoising_model(vec.to('cuda'), t2.to('cuda'), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67bf5c",
   "metadata": {},
   "source": [
    "**Check timestep embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_gen = estimator.generative_model.sample(batch_size=1000,\n",
    "#                                              y=None, \n",
    "#                                    `          return_all_timesteps=False,\n",
    "#                                              clip_denoised=True)\n",
    "\n",
    "X_gen= estimator.generative_model.ddim_sample(batch_size=1000, \n",
    "                      y=None, \n",
    "                      return_all_timesteps = False, \n",
    "                      ddim_sampling_eta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdce774",
   "metadata": {},
   "source": [
    "**Plot generated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83689e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_tmp = sc.AnnData(X=X_gen.detach().cpu().numpy())\n",
    "sc.tl.pca(adata_tmp)\n",
    "sc.pp.neighbors(adata_tmp)\n",
    "sc.tl.umap(adata_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for batch in estimator.datamodule.train_dataloader:\n",
    "    d.append(batch[\"X\"])\n",
    "    \n",
    "d = torch.cat(d, dim=0)\n",
    "# d = torch.clip(d, -3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8aae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(X = np.concatenate([X_gen.detach().cpu().numpy(), d.cpu().numpy()]),\n",
    "                   obs = pd.DataFrame({\"type\":[\"gen\"]*len(X_gen)+[\"real\"]*len(d)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38379c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(adata, color=\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cecd296",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171cc928",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gen.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8c1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fab092",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0413719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = 2 * (d - d.min(1).values.unsqueeze(-1)) / (d.max(1).values.unsqueeze(-1) - d.min(1).values.unsqueeze(-1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110609d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = (d - d.min(1).values.unsqueeze(-1)) / (d.max(1).values.unsqueeze(-1) - d.min(1).values.unsqueeze(-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29525a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80643e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:celldreamer]",
   "language": "python",
   "name": "celldreamer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
