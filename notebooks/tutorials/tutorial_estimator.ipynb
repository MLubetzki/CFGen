{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05ea3f3",
   "metadata": {},
   "source": [
    "# Test the estimator class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b531e762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.8/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from celldreamer.estimator.celldreamer_estimator import CellDreamerEstimator\n",
    "from celldreamer.paths import PERT_DATA_DIR\n",
    "from celldreamer.data.utils import Args\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, TQDMProgressBar\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.utilities.model_summary import ModelSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b9127",
   "metadata": {},
   "source": [
    "Initialize the ```args``` dict and the estimator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf2462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pert = Args(\n",
    "                   {   \n",
    "                    #General \n",
    "                    \"train\": True,\n",
    "                    \"experiment_name\": \"try_experiment\",\n",
    "                    \"task\": \"perturbation_modelling\",\n",
    "                    \"freeze_embeddings\": True,\n",
    "                    \"feature_type\": \"grover\",\n",
    "                    \"data_path\": PERT_DATA_DIR / 'sciplex' / 'sciplex_complete_middle_subset.h5ad',\n",
    "                    \"batch_size\": 128, \n",
    "                    \"use_latent_repr\": True,\n",
    "                    \"one_hot_encode_features\": True,\n",
    "                    \"resume\": False,\n",
    "                    \n",
    "                    # Perturbation setting specific\n",
    "                    \"perturbation_key\": \"condition\",\n",
    "                    \"dose_key\": \"dose\",\n",
    "                    \"covariate_keys\": \"cell_type\",\n",
    "                    \"smile_keys\": \"SMILES\",\n",
    "                    \"degs_key\": \"lincs_DEGs\",\n",
    "                    \"pert_category\": \"cov_drug_dose_name\",\n",
    "                    \"split_key\": \"split_ho_pathway\",\n",
    "                    \"use_drugs_idx\":True,\n",
    "                    \"embedding_dimensions\": 100,\n",
    "                    \"one_hot_encode_features\": False,\n",
    "                    \"doser_width\":128,\n",
    "                    \"doser_depth\":3,\n",
    "                     \n",
    "                    # General model \n",
    "                    \"generative_model\":\"diffusion\", \n",
    "                    \"denoising_model\": \"mlp\",\n",
    "                    \n",
    "                    # Autoencoder \n",
    "                    \"autoencoder_kwargs\": {\"in_dim\": 2000,\n",
    "                                  \"batch_size\": 32, \n",
    "                                  \"hidden_dim_encoder\": [256, 128, 64], \n",
    "                                  \"hidden_dim_decoder\": [64, 128, 64], \n",
    "                                  \"batch_norm\": True, \n",
    "                                  \"layer_norm\": False,\n",
    "                                  \"activation\": torch.nn.ReLU,\n",
    "                                  \"output_activation\": torch.nn.Identity, \n",
    "                                  \"reconst_loss\": \"mse\", \n",
    "                                  \"dropout\": 0.0,\n",
    "                                  \"weight_decay\": 0.1, \n",
    "                                  \"learning_rate\": 0.001,\n",
    "                                  \"optimizer\": torch.optim.Adam, \n",
    "                                  \"lr_scheduler\": None,\n",
    "                                  \"lr_scheduler_kwargs\": None\n",
    "                                  },\n",
    "                    \n",
    "                    # Denoising model specific \n",
    "                    \"denoising_module_kwargs\": \n",
    "                        {\n",
    "                         \"dims\": [128, 64],\n",
    "                         \"time_embed_size\": 100, \n",
    "                         \"class_emb_size\": 100,\n",
    "                         \"dropout\": 0.0\n",
    "                        }, \n",
    "                    \n",
    "                    # Diffusion model specific\n",
    "                    \"generative_model_kwargs\": \n",
    "                        {\n",
    "                         \"T\": 4.000, \n",
    "                         \"w\": 0.3, \n",
    "                         \"v\": 0.2,\n",
    "                         \"p_uncond\": 0.2, \n",
    "                         \"logging_freq\": 1000,  \n",
    "                         \"classifier_free\": False\n",
    "                        },\n",
    "                    \n",
    "                    # Autoencoder trainer hparams\n",
    "                    \"trainer_autoencoder_kwargs\": {\n",
    "                        'max_epochs': 1000,\n",
    "                        'gradient_clip_val': 1.,\n",
    "                        'gradient_clip_algorithm': 'norm',\n",
    "                        'default_root_dir': \"\",\n",
    "                        'accelerator': 'gpu',\n",
    "                        'devices': 1,\n",
    "                        'num_sanity_val_steps': 0,\n",
    "                        'check_val_every_n_epoch': 1,\n",
    "                        'log_every_n_steps': 100,\n",
    "                        'detect_anomaly': False,\n",
    "                        'enable_progress_bar': True,\n",
    "                        'enable_model_summary': False,\n",
    "                        'enable_checkpointing': True},  \n",
    "                       \n",
    "                    # Generative model trainer hyperparams \n",
    "                    \"trainer_generative_kwargs\": {\n",
    "                        'max_epochs': 1000,\n",
    "                        'gradient_clip_val': 1.,\n",
    "                        'gradient_clip_algorithm': 'norm',\n",
    "                        'default_root_dir': \"\",\n",
    "                        'accelerator': 'gpu',\n",
    "                        'devices': 1,\n",
    "                        'num_sanity_val_steps': 0,\n",
    "                        'check_val_every_n_epoch': 1,\n",
    "                        'log_every_n_steps': 100,\n",
    "                        'detect_anomaly': False,\n",
    "                        'enable_progress_bar': True,\n",
    "                        'enable_model_summary': False,\n",
    "                        'enable_checkpointing': True}                 \n",
    "                 })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd5511c",
   "metadata": {},
   "source": [
    "Initialize the cell estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426560c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the training folders...\n",
      "Initialize data module...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize feature embeddings...\n",
      "Initialize model...\n"
     ]
    }
   ],
   "source": [
    "estimator = CellDreamerEstimator(args_pert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194efee5",
   "metadata": {},
   "source": [
    "Check feature embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e43d443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drug': 3400, 'cell_type': 100}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.args.denoising_module_kwargs[\"num_classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62755f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drug': DrugsFeaturizer(\n",
       "   (features): Embedding(188, 3400)\n",
       "   (dosers): MLP(\n",
       "     (0): Linear(in_features=3401, out_features=128, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Dropout(p=0.0, inplace=True)\n",
       "     (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (4): ReLU(inplace=True)\n",
       "     (5): Dropout(p=0.0, inplace=True)\n",
       "     (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (7): ReLU(inplace=True)\n",
       "     (8): Dropout(p=0.0, inplace=True)\n",
       "     (9): Linear(in_features=128, out_features=1, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'cell_type': CategoricalFeaturizer(\n",
       "   (embeddings): Embedding(3, 100)\n",
       " )}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.feature_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f64b4",
   "metadata": {},
   "source": [
    "Check training batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8852f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0428, 0.0000, 0.4773,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5781,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.6152,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5222,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " 'X_degs': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'y': {'y_drug': [tensor([ 40, 187, 162,  68,  56,  54, 132, 185,  46, 161,  73, 117,   3, 136,\n",
       "           159, 178, 179,  76,  79, 105,  48, 123, 111,  11, 140, 182, 149, 105,\n",
       "           120, 125,  70,  85, 172,  41, 172, 167, 117, 119,  60, 170,  88, 181,\n",
       "            87, 120,  91, 148, 130,  82, 129,   2, 100,   2, 168,  10, 180, 187,\n",
       "           121,  31, 178, 174, 152, 165, 169,  26,  97,  17,  14, 145, 154, 142,\n",
       "            14, 145, 122,  83, 111,  35,  48,   8,  89,  19,  71, 137,  89,  61,\n",
       "           113,  55, 173, 181,  32, 187,  72, 104, 138,   9,  53,  16,  64, 153,\n",
       "           107, 129, 187,  98, 116,   9, 168,  16,  79,  66, 168, 187,  15,  10,\n",
       "           118,  59,  95,  36,   1,  93, 127,  52, 162,  53,  69,  19,   1, 146,\n",
       "           187,  43]),\n",
       "   tensor([  100.,     0.,   100.,    10.,    10., 10000.,    10.,    10., 10000.,\n",
       "             100.,  1000., 10000.,  1000.,   100.,   100.,   100.,    10.,    10.,\n",
       "            1000., 10000.,    10., 10000., 10000.,  1000., 10000., 10000., 10000.,\n",
       "            1000., 10000.,    10.,  1000.,  1000.,    10.,   100., 10000.,  1000.,\n",
       "           10000.,   100.,    10.,   100., 10000.,    10., 10000.,    10.,   100.,\n",
       "            1000.,   100., 10000.,   100., 10000.,   100., 10000.,   100.,   100.,\n",
       "              10.,     0., 10000.,  1000.,  1000., 10000.,   100., 10000., 10000.,\n",
       "            1000., 10000., 10000., 10000., 10000.,  1000.,  1000.,  1000., 10000.,\n",
       "              10., 10000., 10000., 10000., 10000., 10000.,  1000.,    10.,   100.,\n",
       "           10000., 10000.,  1000.,   100., 10000., 10000.,  1000.,  1000.,     0.,\n",
       "            1000.,   100.,  1000.,  1000.,   100.,    10.,  1000.,    10.,  1000.,\n",
       "             100.,     0., 10000., 10000.,    10.,   100.,    10., 10000.,  1000.,\n",
       "            1000.,     0.,   100.,   100.,   100.,  1000.,   100., 10000.,    10.,\n",
       "             100., 10000., 10000.,  1000.,  1000.,    10., 10000.,  1000.,   100.,\n",
       "               0.,  1000.])],\n",
       "  'y_cell_type': tensor([[0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.]])}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(estimator.datamodule.train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ee783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
