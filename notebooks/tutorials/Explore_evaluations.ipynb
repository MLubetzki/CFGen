{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Create a random adata object with data X (100, 20) random floats and as obs categories {C1, C2, C3}, Ci ~ Cat(0, 1, 2, 3, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as skm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gv/b56jzzws1_923v86q0020jknzdcmt7/T/ipykernel_65506/3454745513.py:12: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  adata = ad.AnnData(X, obs=obs)\n",
      "/Users/till.richter/opt/anaconda3/envs/celldreamer/lib/python3.10/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/var/folders/gv/b56jzzws1_923v86q0020jknzdcmt7/T/ipykernel_65506/3454745513.py:13: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  adata_sim = ad.AnnData(X_sim, obs=obs_sim)\n",
      "/Users/till.richter/opt/anaconda3/envs/celldreamer/lib/python3.10/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(100, 20)\n",
    "X_sim = np.random.rand(100, 20)\n",
    "\n",
    "obs = pd.DataFrame(np.random.randint(0, 5, size=(100, 1)), columns=['C1'])\n",
    "obs['C2'] = np.random.randint(0, 5, size=(100, 1))\n",
    "obs['C3'] = np.random.randint(0, 5, size=(100, 1))\n",
    "\n",
    "obs_sim = pd.DataFrame(np.random.randint(0, 5, size=(100, 1)), columns=['C1'])\n",
    "obs_sim['C2'] = np.random.randint(0, 5, size=(100, 1))\n",
    "obs_sim['C3'] = np.random.randint(0, 5, size=(100, 1))\n",
    "\n",
    "adata = ad.AnnData(X, obs=obs)\n",
    "adata_sim = ad.AnnData(X_sim, obs=obs_sim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "    C1  C2  C3\n0    3   0   3\n1    2   1   3\n2    4   0   1\n3    1   1   1\n4    0   0   4\n..  ..  ..  ..\n95   0   3   2\n96   1   4   1\n97   1   2   1\n98   2   2   0\n99   1   4   3\n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C1</th>\n      <th>C2</th>\n      <th>C3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "AnnData object with n_obs × n_vars = 100 × 20\n    obs: 'C1', 'C2', 'C3'"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_sim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def get_unique_attr_combinations(adata):\n",
    "    \"\"\"\n",
    "    Get a list of dictionaries of all unique combinations of categories\n",
    "    :param adata: adata with categories in obs\n",
    "    :return: list of dictionaries of all unique combinations of categories\n",
    "    \"\"\"\n",
    "    # Get a list of dictionaries of all unique combinations of categories\n",
    "    unique_categories = []\n",
    "    # Loop over cells (rows) in adata\n",
    "    for i, cell in adata.obs.iterrows():\n",
    "        # Load the set of categories as dictionary with category name as key and category value as value\n",
    "        categories = cell.to_dict()\n",
    "        # If categories is not in unique_categories, append it\n",
    "        if categories not in unique_categories:\n",
    "            unique_categories.append(categories)\n",
    "    return unique_categories"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Reconstruction Loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 70 unique categories in real data, 43 categories are also in simulated data\n",
      "MSE:  0.16601801\n",
      "R2:  -1.1507381743212144\n",
      "Explained Variance:  -1.0422202908075773\n"
     ]
    }
   ],
   "source": [
    "def get_reconstruction_loss(adata, adata_sim):\n",
    "\n",
    "    real_unique_categories = get_unique_attr_combinations(adata)\n",
    "    sim_unique_categories = get_unique_attr_combinations(adata_sim)\n",
    "\n",
    "    # get overlapping categories\n",
    "    overlapping_categories = []\n",
    "    for real_category in real_unique_categories:\n",
    "        for sim_category in sim_unique_categories:\n",
    "            if real_category == sim_category:\n",
    "                overlapping_categories.append(real_category)\n",
    "\n",
    "    print('Out of {} unique categories in real data, {} categories are also in simulated data'.format(len(real_unique_categories), len(overlapping_categories)))\n",
    "\n",
    "    mse = []\n",
    "    r2 = []\n",
    "    explained_variance = []\n",
    "\n",
    "    for category in overlapping_categories:\n",
    "        for i, cell in adata.obs.iterrows():\n",
    "            true_categories = cell.to_dict()\n",
    "            # check if all categories are the same\n",
    "            if all(true_categories[category] == value for category, value in category.items()):\n",
    "                reference_cell = adata.X[int(i)]\n",
    "\n",
    "        for i, cell in adata_sim.obs.iterrows():\n",
    "            sim_categories = cell.to_dict()\n",
    "            # check if all categories are the same\n",
    "            if all(sim_categories[category] == value for category, value in category.items()):\n",
    "                sim_cell = adata_sim.X[int(i)]\n",
    "                mse.append(skm.mean_squared_error(reference_cell, sim_cell))\n",
    "                r2.append(skm.r2_score(reference_cell, sim_cell))\n",
    "                explained_variance.append(skm.explained_variance_score(reference_cell, sim_cell))\n",
    "\n",
    "    # Take the mean of the reconstruction errors for each category\n",
    "    mse = np.mean(mse)\n",
    "    r2 = np.mean(r2)\n",
    "    explained_variance = np.mean(explained_variance)\n",
    "    return mse, r2, explained_variance\n",
    "\n",
    "mse, r2, explained_variance = get_reconstruction_loss(adata, adata_sim)\n",
    "print('MSE: ', mse)\n",
    "print('R2: ', r2)\n",
    "print('Explained Variance: ', explained_variance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Merel's metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "{'mean_prop_real': 0.48699999999999993,\n 'mean_prop_sim': 0.513,\n 'mean_prop_expected': 0.5,\n 'sim_entropy': 94.36566991896672,\n 'cat_match': 0.005}"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def evaluate_knn_graph(adata, adata_sim, k, cat_vars):\n",
    "    \"\"\"\n",
    "    Evaluate the quality of a simulated kNN graph by comparing it to the real kNN graph.\n",
    "    cat_vars:\n",
    "    mean_prop_real: the average proportion of real cells among the k nearest neighbors of each simulated cell. Higher values indicate better simulated data.\n",
    "    mean_prop_sim: the average proportion of simulated cells among the k nearest neighbors of each simulated cell. Lower values indicate better simulated data.\n",
    "    mean_prop_expected: the expected proportion of real cells among the k nearest neighbors of each simulated cell, assuming an equal number of real and simulated cells. This value is always 0.5, but we compute it here for completeness.\n",
    "    sim_entropy: the entropy of the proportion of simulated cells among the k nearest neighbors of each simulated cell. This metric measures how uniformly distributed the simulated cells are around each simulated cell. Lower values indicate better simulated data.\n",
    "    cat_match: the fraction of the k nearest neighbors of each simulated cell that have the same categorical data as the simulated cell. Higher values indicate better simulated data.\n",
    "    :param adata:\n",
    "    :param adata_sim:\n",
    "    :param k:\n",
    "    :param cat_vars:\n",
    "    :return: mean_prop_real, mean_prop_sim, mean_prop_expected, sim_entropy, cat_match\n",
    "    \"\"\"\n",
    "    # Extract X and categorical data from real and simulated datasets\n",
    "    X = np.concatenate((adata.X, adata_sim.X))\n",
    "    cat_data = np.concatenate((adata.obs[cat_vars].values, adata_sim.obs[cat_vars].values))\n",
    "    n_sim = adata_sim.X.shape[0]\n",
    "\n",
    "    # Build kNN graph for simulated data\n",
    "    neigh = NearestNeighbors(n_neighbors=k+1, metric='euclidean')\n",
    "    neigh.fit(X)\n",
    "    sim_indices = np.arange(adata.X.shape[0], X.shape[0])\n",
    "    distances, indices = neigh.kneighbors(adata_sim.X)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    real_counts = np.sum(indices[:, 1:] < adata.X.shape[0], axis=1)\n",
    "    prop_real = real_counts / k\n",
    "    prop_sim = 1 - prop_real\n",
    "    prop_expected = np.full(n_sim, 0.5)\n",
    "    sim_entropy = -np.sum((prop_sim * np.log2(prop_sim)) + (prop_real * np.log2(prop_real)))\n",
    "\n",
    "    # Compute fraction of neighbors with the same categorical data\n",
    "    cat_match = np.mean(np.all(cat_data[indices[:, 1:]] == np.repeat(adata_sim.obs[cat_vars].values[:, np.newaxis, :], k, axis=1), axis=2))\n",
    "\n",
    "    # Return evaluation metrics\n",
    "    return {\n",
    "        'mean_prop_real': np.mean(prop_real),\n",
    "        'mean_prop_sim': np.mean(prop_sim),\n",
    "        'mean_prop_expected': np.mean(prop_expected),\n",
    "        'sim_entropy': sim_entropy,\n",
    "        'cat_match': cat_match\n",
    "    }\n",
    "\n",
    "# get categories in adata\n",
    "cat_vars = adata.obs.columns.values\n",
    "knn_eval = evaluate_knn_graph(adata, adata_sim, 10, cat_vars)\n",
    "knn_eval"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Coverage and Density"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "ename": "QhullError",
     "evalue": "QH6235 qhull error (qh_memalloc): negative request size (-1890208696).  Did int overflow due to high-D?\n\nWhile executing:  | qhull i Qx Qt\nOptions selected for Qhull 2019.1.r 2019/06/21:\n  run-id 1704037748  incidence  Qxact-merge  Qtriangulate  _zero-centrum\n  Q3-no-merge-vertices-dim-high  _max-width  1  Error-roundoff 2e-14\n  _one-merge 8.3e-13  _near-inside 4.2e-12  Visible-distance 1.2e-13\n  U-max-coplanar 1.2e-13  Width-outside 2.4e-13  _wide-facet 7.3e-13\n  _maxoutside 8.5e-13\nLast point added to hull was p33.\n\nAt error exit:\n\nConvex hull of 100 points in 20-d:\n\n  Number of vertices: 41\n  Number of facets: 16363532\n\nStatistics for:  | qhull i Qx Qt\n\n  Number of points processed: 40\n  Number of hyperplanes created: 20390585\n  Number of distance tests for qhull: 20569385\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mQhullError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[58], line 38\u001B[0m\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;66;03m# Return evaluation metrics\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m     32\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mann_real\u001B[39m\u001B[38;5;124m'\u001B[39m: ann_real,\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mann_sim\u001B[39m\u001B[38;5;124m'\u001B[39m: ann_sim,\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoverage_real\u001B[39m\u001B[38;5;124m'\u001B[39m: coverage_real,\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoverage_sim\u001B[39m\u001B[38;5;124m'\u001B[39m: coverage_sim\n\u001B[1;32m     36\u001B[0m     }\n\u001B[0;32m---> 38\u001B[0m coverage_eval \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_coverage\u001B[49m\u001B[43m(\u001B[49m\u001B[43madata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madata_sim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAverage nearest neighbor distance for real cells: \u001B[39m\u001B[38;5;124m'\u001B[39m, coverage_eval[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mann_real\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "Cell \u001B[0;32mIn[58], line 22\u001B[0m, in \u001B[0;36mevaluate_coverage\u001B[0;34m(adata, adata_sim)\u001B[0m\n\u001B[1;32m     19\u001B[0m ann_sim \u001B[38;5;241m=\u001B[39m kdt_real\u001B[38;5;241m.\u001B[39mquery(adata_sim\u001B[38;5;241m.\u001B[39mX, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)[\u001B[38;5;241m0\u001B[39m][:, \u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Compute coverage of real and simulated cells\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m hull_real \u001B[38;5;241m=\u001B[39m \u001B[43mConvexHull\u001B[49m\u001B[43m(\u001B[49m\u001B[43madata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m hull_sim \u001B[38;5;241m=\u001B[39m ConvexHull(adata_sim\u001B[38;5;241m.\u001B[39mX)\n\u001B[1;32m     24\u001B[0m volume_real \u001B[38;5;241m=\u001B[39m hull_real\u001B[38;5;241m.\u001B[39mvolume\n",
      "File \u001B[0;32m_qhull.pyx:2458\u001B[0m, in \u001B[0;36mscipy.spatial._qhull.ConvexHull.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_qhull.pyx:353\u001B[0m, in \u001B[0;36mscipy.spatial._qhull._Qhull.__init__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mQhullError\u001B[0m: QH6235 qhull error (qh_memalloc): negative request size (-1890208696).  Did int overflow due to high-D?\n\nWhile executing:  | qhull i Qx Qt\nOptions selected for Qhull 2019.1.r 2019/06/21:\n  run-id 1704037748  incidence  Qxact-merge  Qtriangulate  _zero-centrum\n  Q3-no-merge-vertices-dim-high  _max-width  1  Error-roundoff 2e-14\n  _one-merge 8.3e-13  _near-inside 4.2e-12  Visible-distance 1.2e-13\n  U-max-coplanar 1.2e-13  Width-outside 2.4e-13  _wide-facet 7.3e-13\n  _maxoutside 8.5e-13\nLast point added to hull was p33.\n\nAt error exit:\n\nConvex hull of 100 points in 20-d:\n\n  Number of vertices: 41\n  Number of facets: 16363532\n\nStatistics for:  | qhull i Qx Qt\n\n  Number of points processed: 40\n  Number of hyperplanes created: 20390585\n  Number of distance tests for qhull: 20569385\n\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import ConvexHull, cKDTree\n",
    "\n",
    "def evaluate_coverage(adata, adata_sim):\n",
    "    \"\"\"\n",
    "    Evaluate the coverage and density of simulated cells by comparing them to the real cells.\n",
    "    stats:\n",
    "    ann_real: the average nearest neighbor distance for the real cells.\n",
    "    ann_sim: the average nearest neighbor distance for the simulated cells.\n",
    "    coverage_real: the proportion of high-dimensional space covered by the real cells.\n",
    "    coverage_sim: the proportion of high-dimensional space covered by the simulated cells.\n",
    "    :param adata:\n",
    "    :param adata_sim:\n",
    "    :return: stats\n",
    "    \"\"\"\n",
    "    # Compute average nearest neighbor distance (ANN) for real and simulated cells\n",
    "    kdt_real = cKDTree(adata.X)\n",
    "    kdt_sim = cKDTree(adata_sim.X)\n",
    "    ann_real = kdt_real.query(adata.X, k=2)[0][:, 1].mean()\n",
    "    ann_sim = kdt_real.query(adata_sim.X, k=2)[0][:, 1].mean()\n",
    "\n",
    "    # Compute coverage of real and simulated cells\n",
    "    hull_real = ConvexHull(adata.X)\n",
    "    hull_sim = ConvexHull(adata_sim.X)\n",
    "    volume_real = hull_real.volume\n",
    "    volume_sim = hull_sim.volume\n",
    "    intersection = ConvexHull(np.concatenate((adata.X, adata_sim.X))).volume\n",
    "    coverage_real = intersection / volume_real\n",
    "    coverage_sim = intersection / volume_sim\n",
    "\n",
    "    # Return evaluation metrics\n",
    "    return {\n",
    "        'ann_real': ann_real,\n",
    "        'ann_sim': ann_sim,\n",
    "        'coverage_real': coverage_real,\n",
    "        'coverage_sim': coverage_sim\n",
    "    }\n",
    "\n",
    "coverage_eval = evaluate_coverage(adata, adata_sim)\n",
    "print('Average nearest neighbor distance for real cells: ', coverage_eval['ann_real'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4) Clustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/till.richter/opt/anaconda3/envs/celldreamer/lib/python3.10/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "/Users/till.richter/opt/anaconda3/envs/celldreamer/lib/python3.10/site-packages/anndata/_core/anndata.py:1785: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  [AnnData(sparse.csr_matrix(a.shape), obs=a.obs) for a in all_adatas],\n",
      "/Users/till.richter/opt/anaconda3/envs/celldreamer/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'ari': 0.007863385190298795}"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_clustering(adata, adata_sim, categories):\n",
    "    # Combine real and simulated data\n",
    "    adata_combined = adata.concatenate(adata_sim)\n",
    "\n",
    "    # Concatenate all categorical variables into a single variable\n",
    "    combined_categories = pd.concat(\n",
    "        [adata_combined.obs[c].astype(str) for c in categories],\n",
    "        axis=1,\n",
    "        join=\"inner\",\n",
    "    ).apply(lambda x: \"\".join(x), axis=1).values\n",
    "\n",
    "    # Compute clustering on combined data\n",
    "    kmeans = KMeans(n_clusters=len(np.unique(combined_categories))).fit(\n",
    "        adata_combined.X\n",
    "    )\n",
    "\n",
    "    # Compute ARI between true and predicted clusters\n",
    "    ari = adjusted_rand_score(combined_categories, kmeans.labels_)\n",
    "\n",
    "    return {\"ari\": ari}\n",
    "\n",
    "cat_vars = adata.obs.columns.values\n",
    "metrics = evaluate_clustering(adata, adata_sim, cat_vars)\n",
    "metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}