args:
  # General training config 
  train: True  # Whether to train the model 
  experiment_name: try_experiment  
  task: perturbation_modelling # task (cell_generation or perturbation_modelling)
  dataset_path: sciplex/sciplex_complete_middle_subset.h5ad
  batch_size: 256  
  resume: False
  train_autoencoder: False # Train autoencoder or only the diffusion model
  use_latent_repr: False # Latent diffusion or direct data feature diffusion 
  pretrained_autoencoder: False
  checkpoint_autoencoder: Null  
  pretrained_generative: False
  chekpoint_path: Null  
  
  # Perturbation setting specific
  perturbation_key: condition 
  dose_key: dose
  covariate_keys: cell_type
  smile_keys: SMILES
  degs_key: lincs_DEGs
  pert_category: cov_drug_dose_name
  split_key: split_ho_pathway
  use_drugs: True
  feature_type: ECFP
  freeze_embeddings: True  # Whether the embeddings should get trained 
  use_drugs: False  # Use drug or not 
  doser_width: 128
  doser_depth: 3  
  cov_embedding_dimensions: 100  # Dimensionality of t
  one_hot_encode_features: True
             
  # General model 
  generative_model: diffusion  
  denoising_model: mlp
                    
  # Autoencoder 
  autoencoder_kwargs: Null

  # Checkpoint kwargs 
  checkpoint_kwargs: 
    filename: epoch_{epoch:01d}
    monitor: loss/valid_loss
    mode: min
    save_last: True
    auto_insert_metric_name: False

  # Early stopping kwargs 
  early_stopping_kwargs: 
    monitor: loss/valid_loss
    patience: 20
    mode: min
    min_delta: 0.
    verbose: False
    strict: True
    check_finite: True
    stopping_threshold: Null
    divergence_threshold: Null
    check_on_train_epoch_end: Null

  # Logger kwargs
  logger_kwargs: 
    offline: False
    id: Null 
    anonymous: Null 
    project: celldreamer
    log_model: False 
    prefix: "" 
    tags: []
    job_type: ""   

  #Denoising model specific 
  denoising_module_kwargs: 
    dims: [64]
    encode_class: False
    time_embed_size: 128 
    class_emb_size: 10
    dropout: 0.0
                  
  # Diffusion model specific
  generative_model_kwargs: 
    T: 1000
    w: 0.3
    p_uncond: 0.2
    classifier_free: False
    learning_rate: 0.0001
    weight_decay: 0.0001
                  
  # Autoencoder trainer hparams
  trainer_kwargs:
    max_epochs: 100
    gradient_clip_val: 1.
    gradient_clip_algorithm: norm
    accelerator: gpu
    devices: 1
    check_val_every_n_epoch: 1
    log_every_n_steps: 1
    detect_anomaly: False
    deterministic: False
                    